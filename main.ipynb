{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc14b6c-301f-443b-bc32-b6334c7bbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575ce89-1d22-49c7-8671-1e7defddaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'roblox_games_data.csv'\n",
    "# Load the latest version\n",
    "df = kagglehub.dataset_load(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"databitio/roblox-games-data\",\n",
    "    file_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aab3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.drop([\"URL\",\"Creator\",\"Date Created\" , \"Server Size\" , \"Last Updated\" , \"Date\" , \"Unnamed: 0\" ],axis=1 , inplace=True)\n",
    "df.drop_duplicates(subset=\"Title\",inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d30609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.tail()\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7435a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aacb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2903db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Genre\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"Genre\"].astype(str) + \" \" + df[\"Title\"].astype(str) + \" \" + df[\"Category\"].astype(str)\n",
    "# รวม cols ที่เป็น text เป็นข้อความ เพราะ TF-IDF มันเหมาะกับงานพวก NLP\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa36faa",
   "metadata": {},
   "source": [
    "# เริ่ม ทำ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e0bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ทำ tf-idf\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    # ลบ emoji + special chars, เหลือเฉพาะตัวอักษร a-z และตัวเลข\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    # ลบช่องว่างซ้ำ\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "\n",
    "# Tokenize เป็นคำเล็ก ๆ\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(text):\n",
    "    text = clean_text(text)\n",
    "    return [stemmer.stem(w) for w in text.split()]\n",
    "\n",
    "# TF: Term Frequency ของแต่ละคำในเอกสาร\n",
    "def compute_tf(text):\n",
    "    words = tokenize(text)\n",
    "    return Counter(words)\n",
    "\n",
    "# IDF: Inverse Document Frequency ของแต่ละคำใน corpus\n",
    "def compute_idf(df, text_columns=['Title','Description']):\n",
    "    N = len(df)\n",
    "    idf = {}\n",
    "    doc_freq = defaultdict(int)\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        words_in_doc = set()\n",
    "        for col in text_columns:\n",
    "            text = str(row.get(col, ''))\n",
    "            words_in_doc.update(tokenize(text))\n",
    "        for word in words_in_doc:\n",
    "            doc_freq[word] += 1\n",
    "\n",
    "    for word, df_count in doc_freq.items():\n",
    "        idf[word] = math.log((N + 1) / (df_count + 1)) + 1\n",
    "    return idf\n",
    "\n",
    "\n",
    "# TF-IDF vector\n",
    "def compute_tfidf(text, idf):\n",
    "    tf = compute_tf(text)\n",
    "    tfidf = {word: tf[word] * idf.get(word, 0.0) for word in tf}\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "    sum1 = sum([v**2 for v in vec1.values()])\n",
    "    sum2 = sum([v**2 for v in vec2.values()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "    return numerator / denominator if denominator else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ab8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_similarity(row, query, idf, title_weight=3):\n",
    "    title_text = str(row['Title'])\n",
    "    desc_text = str(row.get('Description',''))\n",
    "\n",
    "    # duplicate title words\n",
    "    combined = (\" \".join([title_text]*title_weight)) + \" \" + desc_text\n",
    "\n",
    "    tfidf_doc = compute_tfidf(combined, idf)\n",
    "    tfidf_query = compute_tfidf(query, idf)\n",
    "    return cosine_similarity(tfidf_doc, tfidf_query)\n",
    "\n",
    "def compute_features_for_query(df, query):\n",
    "    idf = compute_idf(df, text_columns=['Title','Description'])  # ใช้ Title + Description ก็ได้\n",
    "    df['text_similarity'] = df.apply(lambda r: text_similarity(r, query, idf), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcfe5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_number(s):\n",
    "    if not isinstance(s, str):\n",
    "        return float(s)\n",
    "    s = s.replace('+','').replace(',','').strip()\n",
    "    if s.endswith('M'):\n",
    "        return float(s[:-1]) * 1_000_000\n",
    "    elif s.endswith('K'):\n",
    "        return float(s[:-1]) * 1_000\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# แปลงคอลัมน์\n",
    "df['Total Visits_num'] = df['Total Visits'].apply(parse_number)\n",
    "df['Favorites_num'] = df['Favorites'].apply(parse_number)\n",
    "df['Active Users_num'] = df['Active Users'].apply(parse_number)\n",
    "\n",
    "# normalize\n",
    "df['visit_ratio_norm'] = df['Total Visits_num'] / df['Total Visits_num'].max()\n",
    "df['fav_ratio_norm'] = df['Favorites_num'] / df['Favorites_num'].max()\n",
    "df['active_ratio_norm'] = df['Active Users_num'] / df['Active Users_num'].max()\n",
    "\n",
    "\n",
    "def train_linear_regression(X, y):\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]  # add bias\n",
    "    beta = np.linalg.pinv(X_b) @ y           # ใช้ pseudo-inverse\n",
    "    return beta\n",
    "\n",
    "\n",
    "def predict_linear_regression(X, beta):\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "    return X_b @ beta\n",
    "\n",
    "# สร้าง mapping ของ genre เป็น score\n",
    "genre_mapping = {\n",
    "    'Building': 0.6,\n",
    "    'All Genres': 0.5,\n",
    "    'Adventure': 0.7,\n",
    "    'Fighting': 0.8,\n",
    "    'RPG': 0.9,\n",
    "    'Military': 0.7,\n",
    "    'Town and City': 0.6,\n",
    "    'Horror': 0.8,\n",
    "    'FPS': 0.85,\n",
    "    'Comedy': 0.5,\n",
    "    'Naval': 0.6,\n",
    "    'Sports': 0.7,\n",
    "    'Sci-Fi': 0.8\n",
    "}\n",
    "\n",
    "df['genre_score'] = df['Genre'].map(genre_mapping).fillna(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6955ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. คำนวณ IDF ครอบคลุม Title + Description\n",
    "idf = compute_idf(df, text_columns=['Title','Description'])\n",
    "\n",
    "# 2. TF-IDF similarity\n",
    "query = \"Obby\"\n",
    "df['text_similarity'] = df.apply(lambda r: text_similarity(r, query, idf, title_weight=3), axis=1)\n",
    "\n",
    "# 3. กรองเฉพาะแถวที่ text_similarity > 0\n",
    "df_filtered = df[(df['text_similarity'] > 0)].copy()\n",
    "\n",
    "# 4. สร้าง X matrix สำหรับ regression\n",
    "X_train = df_filtered[['text_similarity','visit_ratio_norm','fav_ratio_norm','genre_score']].values\n",
    "\n",
    "# 5. สร้าง target (ถ้าไม่มี user rating จริง)\n",
    "if 'UserRating' not in df_filtered.columns:\n",
    "    df_filtered['UserRating'] = 0.4 * df_filtered['visit_ratio_norm'] + 0.3 * df_filtered['fav_ratio_norm'] + 0.3 * np.random.rand(len(df_filtered))\n",
    "\n",
    "y_train = df_filtered['UserRating'].values\n",
    "\n",
    "# 6. Train Linear Regression\n",
    "beta = train_linear_regression(X_train, y_train)\n",
    "print(\"Learned coefficients (β):\", beta)\n",
    "\n",
    "# 7. Predict final score\n",
    "df_filtered['final_score'] = predict_linear_regression(X_train, beta)\n",
    "\n",
    "# 8. Sort by final_score\n",
    "df_sorted = df_filtered.sort_values(by='final_score', ascending=False)\n",
    "df_sorted[['Title','text_similarity','visit_ratio_norm','fav_ratio_norm','genre_score','final_score']].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
